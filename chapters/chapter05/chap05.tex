%
% File: chap01.tex
% Author: Victor F. Brena-Medina
% Description: Introduction chapter where the biology goes.
%
\let\textcircled=\pgftextcircled
\chapter{Conclusion and Future Work}
\label{chap:result}
In this chapter, the conclusion and future work have been clarified. For discussion convenience, there are a total of 2 sub-chapters under chapter 5, which we introduced. In section 5.1, we discussed the conclusion part; in section 5.2, we discussed our thesis future work.

\vspace{150mm}
%\vspace{2mm}

%=======
\section{Conclusion}
\label{sec:sec5_1}
This study successfully developed a hybrid Bangla Sign Language recognition system, demonstrating the power of combining transfer learning with machine learning classifiers. By leveraging ResNet50 for feature extraction and employing both SVM and Dense Layer classifiers, the system achieved remarkable accuracy rates of 99.7\% and 99.5\%, respectively. The findings highlight the system's potential to bridge communication gaps for the Bangla-speaking hearing-impaired community, fostering greater social inclusion.

The proposed approach addresses significant challenges in the field, including data diversity and model robustness. However, there remain opportunities for improvement, such as expanding the dataset, enabling dynamic gesture recognition, and deploying real-time systems on low-resource devices. These advancements can further enhance accessibility and usability, paving the way for a universal, multilingual sign language recognition framework. Ultimately, this research serves as a critical step towards empowering the hearing-impaired community through innovative technology.

\section{Future Work}
This research lays the groundwork for Bangla Sign Language (BdSL) recognition but leaves room for several advancements. Future work can focus on enabling dynamic gesture and sentence-level recognition by incorporating models like Recurrent Neural Networks (RNNs) or Temporal Convolutional Networks (TCNs). Expanding the dataset with diverse backgrounds, lighting conditions, and hand orientations will further enhance the model's robustness and inclusivity. Real-time deployment on edge devices such as smartphones or IoT platforms can make the system more accessible, with lightweight architectures like MobileNet or EfficientNet optimizing computational performance. Additionally, integrating multilingual sign language support and exploring neural machine translation can bridge communication gaps across languages. The adoption of Explainable AI (XAI) frameworks will improve user trust by making model predictions more interpretable. Finally, the incorporation of Augmented Reality (AR) could provide real-time feedback for gesture correction and interactive learning tools, paving the way for broader adoption and impact.
\label{sec:sec5_2}